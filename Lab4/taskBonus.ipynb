{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from utils.DataLoader import loadData\n",
    "from utils import Plots\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define N-Layer Residual network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, num_layers):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (7, 7), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D((3, 3))(x)\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        # residual block\n",
    "        residual = x\n",
    "        x = layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.Conv2D(64, (3, 3), padding=\"same\")(x)\n",
    "        x = layers.add([x, residual])\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(9, activation=\"softmax\")(x)\n",
    "\n",
    "    return Model(inputs, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoadData**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/5780 of train images\n",
      "Reading: 100/5780 of train images\n",
      "Reading: 200/5780 of train images\n",
      "Reading: 300/5780 of train images\n",
      "Reading: 400/5780 of train images\n",
      "Reading: 500/5780 of train images\n",
      "Reading: 600/5780 of train images\n",
      "Reading: 700/5780 of train images\n",
      "Reading: 800/5780 of train images\n",
      "Reading: 900/5780 of train images\n",
      "Reading: 1000/5780 of train images\n",
      "Reading: 1100/5780 of train images\n",
      "Reading: 1200/5780 of train images\n",
      "Reading: 1300/5780 of train images\n",
      "Reading: 1400/5780 of train images\n",
      "Reading: 1500/5780 of train images\n",
      "Reading: 1600/5780 of train images\n",
      "Reading: 1700/5780 of train images\n",
      "Reading: 1800/5780 of train images\n",
      "Reading: 1900/5780 of train images\n",
      "Reading: 2000/5780 of train images\n",
      "Reading: 2100/5780 of train images\n",
      "Reading: 2200/5780 of train images\n",
      "Reading: 2300/5780 of train images\n",
      "Reading: 2400/5780 of train images\n",
      "Reading: 2500/5780 of train images\n",
      "Reading: 2600/5780 of train images\n",
      "Reading: 2700/5780 of train images\n",
      "Reading: 2800/5780 of train images\n",
      "Reading: 2900/5780 of train images\n",
      "Reading: 3000/5780 of train images\n",
      "Reading: 3100/5780 of train images\n",
      "Reading: 3200/5780 of train images\n",
      "Reading: 3300/5780 of train images\n",
      "Reading: 3400/5780 of train images\n",
      "Reading: 3500/5780 of train images\n",
      "Reading: 3600/5780 of train images\n",
      "Reading: 3700/5780 of train images\n",
      "Reading: 3800/5780 of train images\n",
      "Reading: 3900/5780 of train images\n",
      "Reading: 4000/5780 of train images\n",
      "Reading: 4100/5780 of train images\n",
      "Reading: 4200/5780 of train images\n",
      "Reading: 4300/5780 of train images\n",
      "Reading: 4400/5780 of train images\n",
      "Reading: 4500/5780 of train images\n",
      "Reading: 4600/5780 of train images\n",
      "Reading: 4700/5780 of train images\n",
      "Reading: 4800/5780 of train images\n",
      "Reading: 4900/5780 of train images\n",
      "Reading: 5000/5780 of train images\n",
      "Reading: 5100/5780 of train images\n",
      "Reading: 5200/5780 of train images\n",
      "Reading: 5300/5780 of train images\n",
      "Reading: 5400/5780 of train images\n",
      "Reading: 5500/5780 of train images\n",
      "Reading: 5600/5780 of train images\n",
      "Reading: 5700/5780 of train images\n",
      "Reading: 0/450 of train images\n",
      "Reading: 100/450 of train images\n",
      "Reading: 200/450 of train images\n",
      "Reading: 300/450 of train images\n",
      "Reading: 400/450 of train images\n"
     ]
    }
   ],
   "source": [
    "img_w, img_h, img_ch = 128, 128, 1\n",
    "rel_path = 'Lab1/X_ray/'\n",
    "\n",
    "# load data\n",
    "x_train, x_test, y_train, y_test = loadData(img_w, img_h, rel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balance training set and create folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_numerosity = np.sum(y_train, axis=0)\n",
    "num_classes = len(class_numerosity)\n",
    "smallest = np.min(class_numerosity)\n",
    "\n",
    "# for each class, choose at random a number of samples equal to the least represented class\n",
    "sampled_indices1, sampled_indices2, sampled_indices3 = [], [], []\n",
    "for i in range(num_classes):\n",
    "    class_indices = np.array(np.where(y_train[:, i] == 1)).flatten()\n",
    "    sampled_class_indices = np.random.choice(class_indices, size=smallest, replace=True)\n",
    "    # create folds\n",
    "    indices1, indices2, indices3 = np.array_split(sampled_class_indices, 3)\n",
    "    sampled_indices1.append(indices1)\n",
    "    sampled_indices2.append(indices2)\n",
    "    sampled_indices3.append(indices3)\n",
    "\n",
    "# stack the indices together\n",
    "fold1 = np.hstack(sampled_indices1)\n",
    "fold2 = np.hstack(sampled_indices2)\n",
    "fold3 = np.hstack(sampled_indices3)\n",
    "\n",
    "# shuffle the indices of the balanced set\n",
    "np.random.shuffle(fold1), np.random.shuffle(fold2), np.random.shuffle(fold3)\n",
    "\n",
    "x_fold1 = x_train[fold1, :, :, :]\n",
    "y_fold1 = y_train[fold1, :]\n",
    "x_fold2 = x_train[fold2, :, :, :]\n",
    "y_fold2 = y_train[fold2, :]\n",
    "x_fold3 = x_train[fold3, :, :, :]\n",
    "y_fold3 = y_train[fold3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 128, 128, 64  3200        ['input_7[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 42, 42, 64)  0           ['conv2d_126[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 42, 42, 64)   36928       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_127[0][0]']             \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 42, 42, 64)   0           ['conv2d_128[0][0]',             \n",
      "                                                                  'max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 42, 42, 64)   0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_129[0][0]']             \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 42, 42, 64)   0           ['conv2d_130[0][0]',             \n",
      "                                                                  'activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 42, 42, 64)   0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_131[0][0]']             \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 42, 42, 64)   0           ['conv2d_132[0][0]',             \n",
      "                                                                  'activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 42, 42, 64)   0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_133[0][0]']             \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 42, 42, 64)   0           ['conv2d_134[0][0]',             \n",
      "                                                                  'activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 42, 42, 64)   0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_135[0][0]']             \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 42, 42, 64)   0           ['conv2d_136[0][0]',             \n",
      "                                                                  'activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 42, 42, 64)   0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_137[0][0]']             \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 42, 42, 64)   0           ['conv2d_138[0][0]',             \n",
      "                                                                  'activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 42, 42, 64)   0           ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_139[0][0]']             \n",
      "                                                                                                  \n",
      " add_66 (Add)                   (None, 42, 42, 64)   0           ['conv2d_140[0][0]',             \n",
      "                                                                  'activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 42, 42, 64)   0           ['add_66[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_141[0][0]']             \n",
      "                                                                                                  \n",
      " add_67 (Add)                   (None, 42, 42, 64)   0           ['conv2d_142[0][0]',             \n",
      "                                                                  'activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 42, 42, 64)   0           ['add_67[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_143[0][0]']             \n",
      "                                                                                                  \n",
      " add_68 (Add)                   (None, 42, 42, 64)   0           ['conv2d_144[0][0]',             \n",
      "                                                                  'activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 42, 42, 64)   0           ['add_68[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 42, 42, 64)   36928       ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 42, 42, 64)   36928       ['conv2d_145[0][0]']             \n",
      "                                                                                                  \n",
      " add_69 (Add)                   (None, 42, 42, 64)   0           ['conv2d_146[0][0]',             \n",
      "                                                                  'activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 42, 42, 64)   0           ['add_69[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['activation_69[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 9)            585         ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 742,345\n",
      "Trainable params: 742,345\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# depth of model\n",
    "num_layers = 10\n",
    "# learning rate\n",
    "learning_rate = 0.001\n",
    "# batch size\n",
    "batch_size = 8\n",
    "\n",
    "# define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# define learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 20:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# compile the model\n",
    "model = resnet((img_w, img_h, img_ch), num_layers)\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate = learning_rate), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use 3-fold cross-validation approach to fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fold 1 as validation set...\n",
      "Using fold 2 as validation set...\n",
      "Using fold 3 as validation set...\n"
     ]
    }
   ],
   "source": [
    "fold_accuracy = []\n",
    "for i in range(1,4,1):\n",
    "    if i == 1:\n",
    "        x_train = np.vstack([x_fold2, x_fold3])\n",
    "        y_train = np.vstack([y_fold2, y_fold3])\n",
    "        x_valid = x_fold1\n",
    "        y_valid = y_fold1\n",
    "        \n",
    "    elif i == 2:\n",
    "        x_train = np.vstack([x_fold1, x_fold3])\n",
    "        y_train = np.vstack([y_fold1, y_fold3])\n",
    "        x_valid = x_fold2\n",
    "        y_valid = y_fold2\n",
    "        \n",
    "    else:\n",
    "        x_train = np.vstack([x_fold1, x_fold2])\n",
    "        y_train = np.vstack([y_fold1, y_fold2])\n",
    "        x_valid = x_fold3\n",
    "        y_valid = y_fold3\n",
    "    # train the model\n",
    "    print(f\"Using fold {i} as validation set...\")\n",
    "    model_fit = model.fit(x_train, y_train, batch_size=batch_size, epochs=100, verbose=0, validation_data=[x_valid, y_valid], callbacks=[early_stopping, lr_scheduler])    \n",
    "    \n",
    "    fold_accuracy.append(np.max(model_fit.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977+-0.008\n"
     ]
    }
   ],
   "source": [
    "fold_mean = np.mean(fold_accuracy)\n",
    "fold_std = np.std(fold_accuracy)\n",
    "print(f\"Accuracy: {fold_mean:.3f}+-{fold_std:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
